introduction
eda
introduction-1
data-types
exercise-1
exercise-2
lists-and-data-frames
exercise-3
exercise-4
exercise-5
loading-viewing-and-summarising-data
exercise-6
exercise-7
exercise-8
exercise-9
exercise-10
data-transformation-with-dplyr
exercise-11
exercise-12
exercise-13
exercise-14
exercise-15
exercise-16
exercise-17
exercise-18
exercise-19
ggplot2
introduction-2
exercise-1-1
exercise-2-1
exercise-3-1
exercise-4-1
exercise-5-1
visual-exploratory-data-analysis
exercise-6-1
exercise-7-1
exercise-8-1
exercise-9-1
exercise-10-1
exercise-11-1
exercise-12-1
exercise-13-1
exercise-14---17
exercise-18-1
exercise-19-1
reg
book
chapter-3
prediction
inference
parametric-methods
non-parametric-approaches
statistical-learning
model-accuracy
residual-sum-of-squares
accuracy-of-the-model
multiple-linear-regression
variable-selection
model-fit
predictions---sources-of-uncertainty
assumptions-of-additivity-and-linearity
potential-problems
summary
chapter-6---model-selection
prediction-accuracy
subset-selection
stepwise-selection
choosing-the-optimal-model
validation-and-cross-validation
chapter-7---shrinkage-methods
ridge-regression
the-lasso
selecting-the-tuning-parameter
resampling-methods
the-validation-set-approach
leave-one-out-cross-validation
k-fold-cross-validation
the-bootstrap
moving-beyond-linearity
polynomial-regression
step-functions
basis-functions
regression-splines
the-splines-basis-representation
choosing-the-number-and-locations-of-the-knots
smoothing-splines
choosing-lambda
local-regression
generalized-additive-models
r4ds---models
lecture---regression-i
model-accuracy-1
lecture---regression-ii
feature-selection-penalization
wrapper-methods
filter-methods
embedded-methods
lecture---regression-iii
polynomial-regression-1
piecewise-regression
basis-functions-1
splines
local-regression-1
practical-regression-i
applications
example-one
example-two
final-words
class
unsup
exercise-1-2
exercise-2-2
exercise-3-2
exercise-4-2
exercise-5-2
exercise-6-2
exercise-7-2
exercise-8-2
exercise-9-2
exercise-10-2
exercise-11-2
exercise-12-2
exercise-13-2
exercise-14-1
exercise-15-1
exercise-16-1
exercise-17-1
exercise-18-2
exercise-19-2
exercise-20
exercise-21
exercise-22
exercise-23
exercise-24
exercise-25
exercise-26
exercise-27
exercise-28
practical-regression-ii
exercise-1-3
exercise-2-3
exercise-3-3
exercise-4-3
exercise-5-3
exercise-6-3
exercise-7-3
exercise-8-3
exercise-9-3
exercise-10-3
exercise-11-3
exercise-12-3
exercise-13-3
exercise-14-2
exercise-15-2
exercise-16-2
exercise-17-2
exercise-18-3
exercise-19-3
practical-regression-iii
exercise-1-4
exercise-2-4
exercise-3-4
exercise-4-4
exercise-5-4
exercise-6-4
exercise-7-4
exercise-8-4
exercise-9-4
exercise-10-4
exercise-11-4
exercise-12-4
exercise-13-4
exercise-14-3
exercise-15-3
exercise-16-3
exercise-17-3
exercise-19-4
book-1
regression-trees
tree-pruning
cost-complexity-pruning-weakest-link-pruning
building-a-regression-tree
trees-versus-linear-models
bagging
out-of-bag-error-estimation
variable-importance-measures
random-forests
boosting
boosting-algorithm
classification
the-bayes-classifier
k-nearest-neighbors
logistic-regression---skipped
linear-discriminant-analysis
lecture-classification-i
classification-1
evaluating-classifiers
lecture-classification-ii
bagging-1
random-forests-1
boosting-1
conclusion
practical-classification-1
exercise-1-5
exercise-2-5
exercise-3-5
exercise-4-5
exercise-5-5
exercise-6-5
exercise-7-5
exercise-8-5
exercise-9-5
exercise-10-5
exercise-11-5
exercise-12-5
exercise-13-5
exercise-14-4
exercise-15-4
exercise-16-4
exercise-17-4
